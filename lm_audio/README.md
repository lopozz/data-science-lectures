# Audio Language Model Architectures [2h]

Last update: 2025-11-25

1. [Text to Speech Fine-tuning Tutorial](https://www.youtube.com/watch?v=5-Dk3ooxn2Q&t=2414s)
2. [Serve a Text to Speech Model with vLLM](https://www.youtube.com/watch?v=I2F9o8totrg&t=68s)
3. [Fine-tune Text to Speech Models in 2025: CSM-1B and Orpheus TTS](https://www.youtube.com/watch?v=vfe8KIm1ubw&t=4199s)
4. [Orpheus Can Speak Any Language](https://canopylabs.ai/releases/orpheus_can_speak_any_language)
5. [Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models](https://arxiv.org/pdf/2311.07919)
6. [The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783)
7. [Moshi: a speech-text foundation model for real-time dialogue](https://arxiv.org/pdf/2410.00037v2)
8. [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers](https://arxiv.org/pdf/2301.02111)
9. [Phonetics and Speech Feature Extraction](https://web.stanford.edu/~jurafsky/slp3/14.pdf)
10. [Text-to-Speech](https://web.stanford.edu/~jurafsky/slp3/16.pdf)
11. [Fine-tune Orpheus or Sesame CSM-1B with Unsloth (Voice Cloning Tutorial)](https://www.youtube.com/watch?v=3iqvBEGS2So&t=15s)
12. [AudioLM: a Language Modeling Approach to Audio Generation](https://arxiv.org/pdf/2209.03143)
13. [Autoregressive Image Generation using Residual Quantization](https://arxiv.org/pdf/2203.01941)
14. [SoundStream: An End-to-End Neural Audio Codec](https://arxiv.org/pdf/2107.03312)
15. [Residual Vector Quantization for Audio and Speech Embeddings](https://www.youtube.com/watch?v=Xt9S74BHsvc)
16. [Audio Language Models - Neil Zeghidour (Moshi)](https://www.youtube.com/watch?v=Zjpl84KCTvw)
17. [High Fidelity Neural Audio Compression](https://arxiv.org/pdf/2210.13438)
18. [SNAC: Multi-Scale Neural Audio Codec](https://arxiv.org/pdf/2410.14411v1)
19. [Towards Human-Sounding TTS](https://canopylabs.ai/model-releases)
20. [Crossing the uncanny valley of conversational voice](https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice)